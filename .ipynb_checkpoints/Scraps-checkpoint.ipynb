{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraps\n",
    "Old code scraps that we aren't using anymore but may want to save for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize nearest neighbors model\n",
    "neigh = NearestNeighbors(n_neighbors=1000, algorithm='brute', metric='cosine')\n",
    "#Fit on the movie ratings we have\n",
    "model = neigh.fit(dfs)\n",
    "m = pd.read_csv(path + \"movies.csv\")\n",
    "def movies_not_seen(df, user_id, matrix, movie_c):\n",
    "    \"\"\"\n",
    "    Determine what movies a user has not seen; \n",
    "    i.e. potential movies to recommend\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): Dataframe of movies with their titles and genres\n",
    "        user_id (int): id for user we want to recommend something to\n",
    "        matrix (csr matrix): user-movie matrix of movie ratings\n",
    "        \n",
    "    Returns:\n",
    "        new (csr matrix): the columns of matrix corresponding to the movies\n",
    "                          that user_id hasn't seen\n",
    "        not_seen (list): the indices of the movies in the user-movie matrix\n",
    "                         that user_id hasn't seen\n",
    "    \"\"\"\n",
    "    #get the movies the user has seen\n",
    "    movieids_seen = df[df.userId == user_id].movieId.values\n",
    "    \n",
    "    #mask is the indices of the movies that userid has seen in the user-movie matrix\n",
    "    mask = []\n",
    "    for i, j in enumerate(movie_c.categories):\n",
    "        if j in df[df.userId == user_id].movieId.values:\n",
    "            mask.append(i)\n",
    "            \n",
    "    #use the mask to get the indices of the movies userid hasn't seen\n",
    "    not_seen = list(set(range(len(movie_c.categories))) - set(mask))\n",
    "    \n",
    "    #cut out the movies (columns) userid has seen from our matrix\n",
    "    new = matrix[:,not_seen]\n",
    "    \n",
    "    return new, not_seen\n",
    "\n",
    "def count_not_seen(df, movie_c, not_seen, indices):\n",
    "    \"\"\"\n",
    "    This function returns the number a times a movie not seen by the user was seen by the user's nearest neighbors\n",
    "    Input:\n",
    "    Output\n",
    "    \"\"\"\n",
    "    #find how many times each movie has been rated by the neighbors\n",
    "    ratings_count = []\n",
    "    #Loop through the movie_ids not seen by our user\n",
    "    for movie_id in np.array(movie_c.categories)[not_seen]:\n",
    "        count = 0\n",
    "        #Loop through the user_ids of our user's neighbor\n",
    "        for id_ in indices + 1:\n",
    "            #Check if the userId has rated the movie\n",
    "            if movie_id in df[df.userId == id_].movieId.values:\n",
    "                count += 1\n",
    "        ratings_count.append(count)\n",
    "    return np.array(ratings_count)\n",
    "\n",
    "def knn_recommend_movies(df, matrix, fitted_model, user_id, n, movie_c):\n",
    "    \"\"\"\n",
    "    This function uses the K-nearest neighbors algorithm to suggest a movie for the user to watch.\n",
    "    \n",
    "    Inputs:\n",
    "    df: sparse dataframe containing user and movie information. Contains columns user_id, movie_id, rating\n",
    "    matrix: sparse matrix containing user_id on the y axis and movie_id on the x_axis, with the rating for each movie in the rows\n",
    "    fitted_model: the type on model we run this clustering method on  \n",
    "    user_id: the user we want to recommend a movie for\n",
    "    n: number of movies to recommend (MAY NOT USE_ CHECK BEFORE FINAL)\n",
    "    \n",
    "    Outputs: \n",
    "    movie_id, title. The id number and title of the recommended movie\n",
    "    \"\"\"\n",
    "    alpha=1      #we recommend 1 movie \n",
    "    new, not_seen = movies_not_seen(df, user_id, matrix, movie_c)\n",
    "    \n",
    "    #Initialize nearest neighbors model\n",
    "    neigh = NearestNeighbors(n_neighbors=1000, algorithm='brute', metric='cosine')\n",
    "    #Fit on the movie ratings we have\n",
    "    model = neigh.fit(sparse_matrix)\n",
    "    \n",
    "    #get the indices for nearest neighbors of userId\n",
    "    indices = fitted_model.kneighbors(matrix[user_id-1], 3)[1][0]\n",
    "    \n",
    "    #neighbors is the actual rows of the matrix with each neighbors ratings\n",
    "    neighbors = new[indices].todense()\n",
    "\n",
    "    #find how many times each movie has been rated by the neighbors\n",
    "    ratings_count = count_not_seen(df, movie_c, not_seen, indices)\n",
    "    \n",
    "    #Choose the movie to recommend (weight frequently-seen-movies higher)\n",
    "    position = np.argmax(np.mean(neighbors - 2.5, axis=0)*alpha*ratings_count.reshape((-1,1)))\n",
    "    \n",
    "    #get the movieid from the matrix column value\n",
    "    movie_id = np.array(movie_c.categories)[not_seen][position]\n",
    "    print('movie_id',movie_id)\n",
    "    return movie_id, m[m.movieId == movie_id].title\n",
    "\n",
    "\n",
    "\n",
    "#FIXME: SPARSE MATRIX IS FILLED WITH 0 NOT 2.5\n",
    "print(knn_recommend_movies(df, sparse_matrix, model, 12, 1, movie_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([[1,1,.5],\n",
    "        [1,6,2],\n",
    "        [2,7,4],\n",
    "        [3,2,4.5],\n",
    "        [3,3,3],\n",
    "        [3,4,1],\n",
    "        [4,1,2],\n",
    "        [5,4,1.5],\n",
    "        [6,3,5],\n",
    "        [7,10,4.5],\n",
    "        [8,5,4.5],\n",
    "        [9,8,.5],\n",
    "        [9,9,1.5],\n",
    "        [10,3,3.5]])\n",
    "df = pd.DataFrame(x,columns=['userId','movieId','rating'])\n",
    "\n",
    "user_c = CategoricalDtype(sorted(df.userId.unique()), ordered=True)\n",
    "movie_c = CategoricalDtype(sorted(df.movieId.unique()), ordered=True)\n",
    "\n",
    "row = df.userId.astype(user_c).cat.codes\n",
    "col = df.movieId.astype(movie_c).cat.codes\n",
    "sparse_matrix = csr_matrix((df['rating'], (row, col)), \\\n",
    "                           shape=(user_c.categories.size, movie_c.categories.size))\n",
    "\n",
    "dense = sparse_matrix.todense()\n",
    "\n",
    "\n",
    "def model(avg_rating, score_from_model, recommend = False):\n",
    "    recommended_score = avg_rating + score_from_model\n",
    "    if recommended_score >= 3.5:\n",
    "        recommend = True\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn_recommend_movies_old(df, matrix, fitted_model, user_id, n):\n",
    "    \"\"\"\n",
    "    This function uses the K-nearest neighbors algorithm to suggest a movie for the user to watch.\n",
    "    \n",
    "    Inputs:\n",
    "    df: sparse dataframe containing user and movie information. Contains columns user_id, movie_id, rating\n",
    "    matrix: sparse matrix containing user_id on the y axis and movie_id on the x_axis, with the rating for each movie in the rows\n",
    "    fitted_model: the type on model we run this clustering method on  \n",
    "    user_id: the user we want to recommend a movie for\n",
    "    n: number of movies to recommend (MAY NOT USE_ CHECK BEFORE FINAL)\n",
    "    \n",
    "    Outputs: \n",
    "    movie_id, title. The id number and title of the recommended movie\n",
    "    \"\"\"\n",
    "    alpha=1\n",
    "    movieids_seen = df[df.userId == user_id].movieId.values\n",
    "    #mask is the indices of the movies that userid has seen in the user-movie matrix\n",
    "    mask = []\n",
    "    for i, j in enumerate(movie_c.categories):\n",
    "        if j in df[df.userId == user_id].movieId.values:\n",
    "            mask.append(i)\n",
    "    #use the mask to get the indices of the movies userid hasn't seen\n",
    "    not_seen = list(set(range(len(movie_c.categories))) - set(mask))\n",
    "    #cut out the movies (columns) userid has seen from our matrix\n",
    "    new = matrix[:,not_seen]\n",
    "    #get the indices for nearest neighbors of userId\n",
    "    indices = fitted_model.kneighbors(matrix[user_id-1], 3)[1][0]\n",
    "    #neighbors is the actual rows of the matrix with each neighbors ratings\n",
    "    neighbors = new[indices].todense()\n",
    "    #find how many times each movie has been rated by the neighbors\n",
    "    neigh_movies = []\n",
    "\n",
    "    #find how many times each movie has been rated by the neighbors\n",
    "    ratings_count = []\n",
    "    #Loop through the movie_ids not seen by our user\n",
    "    for movie_id in np.array(movie_c.categories)[not_seen]:\n",
    "        count = 0\n",
    "        #Loop through the user_ids of our user's neighbor\n",
    "        for id_ in indices + 1:\n",
    "            #Check if the userId has rated the movie\n",
    "            if movie_id in df[df.userId == id_].movieId.values:\n",
    "                count += 1\n",
    "        ratings_count.append(count)\n",
    "    ratings_count = np.array(ratings_count)\n",
    "    #Choose the movie to recommend (weight frequently-seen-movies higher)\n",
    "    position = np.argmax(np.mean(neighbors - 2.5, axis=0)*alpha*ratings_count.reshape((-1,1)))\n",
    "    #get the movieid from the matrix column value\n",
    "    movie_id = np.array(movie_c.categories)[not_seen][position]\n",
    "    print('movie_id',movie_id)\n",
    "    return movie_id, m[m.movieId == movie_id].title\n",
    "\n",
    "print(knn_recommend_movies_old(df, sparse_matrix, model, 12, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KMeans_Test(model, df, n, alpha=1.):\n",
    "    \"\"\"\n",
    "    Test the accuracy of a fitted KMeans clustering model.\n",
    "        To do this we randomly select n movies. For each of these movies\n",
    "        we replace every non-NAN entry to NAN, then predict the new ratings \n",
    "        as the weighted averages of the non-NAN ratings in their KMeans clusters. \n",
    "        The weights are the proportion of neighbor ratings for a movie with respect\n",
    "        to the total number of ratings neighbors have given for all movies the user\n",
    "        hasn't seen. Then compare these predicted ratings with the actual ratings. \n",
    "        Currently using the sum of squared residuals. \n",
    "        Change to softmax loss function??\n",
    "    \n",
    "    Parameters:\n",
    "        model (KMeans): The fitted model\n",
    "        df (DataFrame): The sparse dataframe including NANs that the\n",
    "                        model was trained on\n",
    "        n (int): The number of movies to test on\n",
    "        alpha (float): hyperparameter\n",
    "    \n",
    "    Returns:\n",
    "        score (float): The accuracy of the KMeans clustering\n",
    "        predictions (list): A flattened list of all predictions made\n",
    "        actual (list): A flattened list of all the true ratings\n",
    "    \"\"\"\n",
    "    labels = model.labels_\n",
    "    #Choose indices for the n random movies (sampling with replacement -- Change?)\n",
    "    movie_ids = df.iloc[:,np.random.randint(0, df.shape[1], 5)].columns.values\n",
    "    actual, predictions = np.array([]), list()\n",
    "    for m_id in movie_ids:\n",
    "        #Find the users that have rated the m_id movie\n",
    "        m_rated_mask = df.loc[:,m_id].notnull().values.values\n",
    "        user_ids = df.iloc[m_rated_mask].index.values\n",
    "        #Grab the ratings and store them in the flattened actual list\n",
    "        actual = np.concatenate((actual,df.iloc[m_rated_mask].loc[:,m_id].values.values))\n",
    "        #Find the clusters for each user (df index starts at 1)\n",
    "        clusters = labels[m_rated_mask]\n",
    "        #Calculate the predicted ratings as the average of the ratings\n",
    "        ##of the other users in their clusters. This is different than using the \n",
    "        ##cluster centers because the cluster centers used a dataframe with 2.5\n",
    "        ##filled in for every NaN value\n",
    "        for i, user_id in enumerate(user_ids):\n",
    "            #Remove the user_id from the dataframe for cluster comparisons\n",
    "            #Don't think we need this: temp_df = df[df.index != user_id].copy()\n",
    "            #Now temp_labels must be adjusted to match the indexing of temp_df\n",
    "            #Don't think we need this: temp_labels = np.delete(labels, np.where(m_rated_mask)[0][i])\n",
    "            #Find the ratings for movie m_id given by neighbors\n",
    "            neighbor_ratings = df.iloc[labels == clusters[i]].loc[:,m_id]\n",
    "            #Find the neighbors average ratings for all movies they've rated\n",
    "            neighbor_avgs = df.iloc[labels == clusters[i]].mean(1)\n",
    "            #Find the user's average rating\n",
    "            user_avg = df.loc[user_id].mean()\n",
    "            #Calculate the number of ratings this user's neighbors have given\n",
    "            ##for every movie that this user hasn't seen\n",
    "            #First find the column index for the movie we're considering\n",
    "            within_cluster_index = np.where(df.iloc[labels==clusters[i]].columns.values == m_id)[0][0]\n",
    "            #Include the movie we're testing to the mask of movies our user hasn't seen\n",
    "            not_seen = np.concatenate((df.iloc[labels==clusters[i]].loc[user_id].isnull().values,[within_cluster_index]))\n",
    "            #Calculate the number of ratings neighbors have given for these movies\n",
    "            num_ratings = df.iloc[labels == clusters[i]].iloc[:,not_seen].notnull().sum()\n",
    "            #print(\"Num ratings:\", num_ratings.loc[m_id])\n",
    "            total = num_ratings.sum()\n",
    "            share = (num_ratings/total).loc[m_id]\n",
    "            predict = round(2*(user_avg + (neighbor_ratings - neighbor_avgs).mean()*alpha*share))/2\n",
    "            #If no one else in the cluster has seen the movie, predict will be NaN\n",
    "            ##In this case, replace predict with the user's average movie-rating\n",
    "            if np.isnan(predict):\n",
    "                predict = round(2*user_avg)/2\n",
    "\n",
    "            predictions.append(predict)\n",
    "            \n",
    "\n",
    "    return np.sum((np.array(predictions) - actual)**2), predictions, actual"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
