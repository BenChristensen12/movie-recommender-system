{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KMeans_Test(model, df, n, alpha=1.):\n",
    "    \"\"\"\n",
    "    Test the accuracy of a fitted KMeans clustering model.\n",
    "        To do this we randomly select n movies. For each of these movies\n",
    "        we replace every non-NAN entry to NAN, then predict the new ratings \n",
    "        as the weighted averages of the non-NAN ratings in their KMeans clusters. \n",
    "        The weights are the proportion of neighbor ratings for a movie with respect\n",
    "        to the total number of ratings neighbors have given for all movies the user\n",
    "        hasn't seen. Then compare these predicted ratings with the actual ratings. \n",
    "        Currently using the sum of squared residuals. \n",
    "        Change to softmax loss function??\n",
    "    \n",
    "    Parameters:\n",
    "        model (KMeans): The fitted model\n",
    "        df (DataFrame): The sparse dataframe including NANs that the\n",
    "                        model was trained on\n",
    "        n (int): The number of movies to test on\n",
    "        alpha (float): hyperparameter\n",
    "    \n",
    "    Returns:\n",
    "        score (float): The accuracy of the KMeans clustering\n",
    "        predictions (list): A flattened list of all predictions made\n",
    "        actual (list): A flattened list of all the true ratings\n",
    "    \"\"\"\n",
    "    labels = model.labels_\n",
    "    #Choose indices for the n random movies (sampling with replacement -- Change?)\n",
    "    movie_ids = df.iloc[:,np.random.randint(0, df.shape[1], 5)].columns.values\n",
    "    actual, predictions = np.array([]), list()\n",
    "    for m_id in movie_ids:\n",
    "        #Find the users that have rated the m_id movie\n",
    "        m_rated_mask = df.loc[:,m_id].notnull().values.values\n",
    "        user_ids = df.iloc[m_rated_mask].index.values\n",
    "        #Grab the ratings and store them in the flattened actual list\n",
    "        actual = np.concatenate((actual,df.iloc[m_rated_mask].loc[:,m_id].values.values))\n",
    "        #Find the clusters for each user (df index starts at 1)\n",
    "        clusters = labels[m_rated_mask]\n",
    "        #Calculate the predicted ratings as the average of the ratings\n",
    "        ##of the other users in their clusters. This is different than using the \n",
    "        ##cluster centers because the cluster centers used a dataframe with 2.5\n",
    "        ##filled in for every NaN value\n",
    "        for i, user_id in enumerate(user_ids):\n",
    "            #Remove the user_id from the dataframe for cluster comparisons\n",
    "            #Don't think we need this: temp_df = df[df.index != user_id].copy()\n",
    "            #Now temp_labels must be adjusted to match the indexing of temp_df\n",
    "            #Don't think we need this: temp_labels = np.delete(labels, np.where(m_rated_mask)[0][i])\n",
    "            #Find the ratings for movie m_id given by neighbors\n",
    "            neighbor_ratings = df.iloc[labels == clusters[i]].loc[:,m_id]\n",
    "            #Find the neighbors average ratings for all movies they've rated\n",
    "            neighbor_avgs = df.iloc[labels == clusters[i]].mean(1)\n",
    "            #Find the user's average rating\n",
    "            user_avg = df.loc[user_id].mean()\n",
    "            #Calculate the number of ratings this user's neighbors have given\n",
    "            ##for every movie that this user hasn't seen\n",
    "            #First find the column index for the movie we're considering\n",
    "            within_cluster_index = np.where(df.iloc[labels==clusters[i]].columns.values == m_id)[0][0]\n",
    "            #Include the movie we're testing to the mask of movies our user hasn't seen\n",
    "            not_seen = np.concatenate((df.iloc[labels==clusters[i]].loc[user_id].isnull().values,[within_cluster_index]))\n",
    "            #Calculate the number of ratings neighbors have given for these movies\n",
    "            num_ratings = df.iloc[labels == clusters[i]].iloc[:,not_seen].notnull().sum()\n",
    "            #print(\"Num ratings:\", num_ratings.loc[m_id])\n",
    "            total = num_ratings.sum()\n",
    "            share = (num_ratings/total).loc[m_id]\n",
    "            predict = round(2*(user_avg + (neighbor_ratings - neighbor_avgs).mean()*alpha*share))/2\n",
    "            #If no one else in the cluster has seen the movie, predict will be NaN\n",
    "            ##In this case, replace predict with the user's average movie-rating\n",
    "            if np.isnan(predict):\n",
    "                predict = round(2*user_avg)/2\n",
    "\n",
    "            predictions.append(predict)\n",
    "            \n",
    "\n",
    "    return np.sum((np.array(predictions) - actual)**2), predictions, actual"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
